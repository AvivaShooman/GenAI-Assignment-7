{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12538, 16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1=pd.read_csv('./Data/startup_data/2023-02-27-yc-companies.csv')\n",
    "data2=pd.read_csv('./Data/startup_data/2023-07-13-yc-companies.csv')\n",
    "\n",
    "data = pd.concat([data1, data2], ignore_index=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PMLS\\AppData\\Local\\Temp\\ipykernel_7128\\582290611.py:23: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  result_df = data.groupby('company_name').apply(combine_rows).apply(pd.Series)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def combine_rows(group):\n",
    "    return {\n",
    "        'company_id': ' \\n '.join(group['company_id'].astype(str).unique()),\n",
    "        'short_description': ' \\n '.join(group['short_description'].dropna().unique()),\n",
    "        'long_description': ' \\n '.join(group['long_description'].dropna().unique()),\n",
    "        'batch': ' , '.join(group['batch'].astype(str).dropna().unique()),\n",
    "        'status': ' , '.join(group['status'].astype(str).dropna().unique()),\n",
    "        'tags': ' , '.join(group['tags'].dropna().unique()),\n",
    "        'location': ' , '.join(group['location'].dropna().unique()),\n",
    "        'country': ' , '.join(group['country'].dropna().unique()),\n",
    "        'year_founded': ' , '.join(group['year_founded'].astype(str).dropna().unique()),\n",
    "        'num_founders': ' , '.join(group['num_founders'].astype(str).dropna().unique()),\n",
    "        'founders_names': ' , '.join(group['founders_names'].dropna().unique()),\n",
    "        'team_size': ' , '.join(group['team_size'].astype(str).dropna().unique()),\n",
    "        'website': ' , '.join(group['website'].dropna().unique()),\n",
    "        'cb_url': ' , '.join(group['cb_url'].dropna().unique()),\n",
    "        'linkedin_url': ' , '.join(group['linkedin_url'].dropna().unique())\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "result_df = data.groupby('company_name').apply(combine_rows).apply(pd.Series)\n",
    "result_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_data = []\n",
    "for index, row in result_df.iterrows():\n",
    "    concatenated_string = (\n",
    "        f\"company_name: {row['company_name']} \\n \"\n",
    "        f\"long_description: {row['long_description']} \\n \"\n",
    "        f\"batch: {row['batch']} \\n \"\n",
    "        f\"status: {row['status']} \\n \"\n",
    "        f\"tags: {row['tags']} \\n \"\n",
    "        f\"location: {row['location']} \\n \"\n",
    "        f\"country: {row['country']} \\n \"\n",
    "        f\"year_founded: {row['year_founded']} \\n \"\n",
    "        f\"num_founders: {row['num_founders']} \\n \"\n",
    "        f\"founders_names: {row['founders_names']} \\n \"\n",
    "        f\"team_size: {row['team_size']} \\n \"\n",
    "        f\"website: {row['website']} \\n \"\n",
    "        f\"cb_url: {row['cb_url']} \\n \"\n",
    "        f\"linkedin_url: {row['linkedin_url']} \\n \"\n",
    "    )\n",
    "    whole_data.append(concatenated_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company_name: 0pass \n",
      " long_description: Compromised employee logins are the biggest cybersecurity risk to any business today - causing over 86% of security breaches.\n",
      "\n",
      "0pass is an identity platform that allows organizations to enable the most secure login mechanisms available for every login across their entire company.\n",
      "\n",
      "We replace traditional login methods like passwords with more convenient methods like Windows Hello, TouchID, FaceID, and Yubikeys. Generally these are “passwordless” methods.\n",
      "\n",
      "Even if your employees fall victim to fraudulent emails - hackers will not be able to break into your company - period. We drive down account takeover and password resets by 96%.\n",
      "\n",
      "Contact us to explore passwordless login for your business. \n",
      "Together, we'll be the start of 0 passwords everywhere. \n",
      " 90% of security breaches are caused by a simple employee mistake. \n",
      "\n",
      "Your employee gets a bad link, clicks an email, then types in their password, and maybe even their two-factor code - because it looks just like the normal company login page!\n",
      "\n",
      "Attackers have proven that your MFA is not enough. 0pass allows you to completely circumvent these basic risks by switching to a passwordless login that can't be stolen.\n",
      "\n",
      "Founded by cybersecurity leaders from SpaceX, AWS, and Blue Origin - we're building security tools that solve the biggest problems, without headaches for your employees. \n",
      " batch: W23 \n",
      " status: Active \n",
      " tags: ['Security', 'Identity', 'SaaS'] , [] \n",
      " location: San Francisco \n",
      " country: US \n",
      " year_founded: 2021.0 \n",
      " num_founders: 3 , 2 \n",
      " founders_names: ['Michael Melone', 'Marcello Salvati', 'Noah Stanford'] , ['Noah Stanford', 'Michael Melone'] \n",
      " team_size: 4.0 \n",
      " website: https://0pass.com \n",
      " cb_url: https://www.crunchbase.com/organization/0pass \n",
      " linkedin_url: https://www.linkedin.com/company/0pass/ \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(whole_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "documents = [Document(page_content=doc, metadata={'id': idx}) for idx, doc in enumerate(whole_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_store(docs, embeddings, store_name):\n",
    "    persistent_directory = \"./VectorStores\" + store_name\n",
    "\n",
    "    print(f\"\\n--- Creating vector store {store_name} ---\")\n",
    "\n",
    "    Chroma.from_documents(docs, embeddings, persist_directory=persistent_directory)\n",
    "    \n",
    "    print(f\"--- Finished creating vector store {store_name} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\bot\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "huggingface_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Creating vector store /startup_data_vector_store ---\n",
      "--- Finished creating vector store /startup_data_vector_store ---\n"
     ]
    }
   ],
   "source": [
    "create_vector_store(documents, huggingface_embeddings, \"/startup_data_vector_store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
